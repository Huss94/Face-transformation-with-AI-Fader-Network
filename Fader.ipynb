{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABDELHAMID Hocine - 2100727 \n",
    "# BERIGOKLU Begum - 3702569 \n",
    "# BOUHAFS Zakaria - 28612466\n",
    "# OZKUL Sevan - 3407336\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "# FADER NETWORK\n",
    "\n",
    "In first place you need to downlad the data as explained in the README.md on our github repository : https://github.com/Huss94/FaderNetwork_MLA \\\n",
    "wil download for you the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import subprocess\n",
    "if not os.path.isdir(\"data\"):\n",
    "    print(\"création du fichier data\")\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "\n",
    "\n",
    "# On télécharge directement les images resized pour ne pas a voir a faire le processing\n",
    "if not os.path.isdir(\"data/img_align_celeba_resized\"):\n",
    "    if not os.path.isfile(\"data/img_align_celeba.zip\"):\n",
    "        print(\"téléchargement de align celeba_resized\")\n",
    "        !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pJ3g0FRi1gMbJ1RBocgcsha2_doI-PW-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pJ3g0FRi1gMbJ1RBocgcsha2_doI-PW-\" -O data/img_align_celeba_resized.zip && rm -rf /tmp/cookies.txt\n",
    "\n",
    "    print(\"unziping\")\n",
    "    !unzip -qq data/img_align_celeba_resized.zip -d data/\n",
    "    print(\"unzipping finished\")\n",
    "\n",
    "    print(\"Suppression de img_align_celeba_resized.zip\")\n",
    "    !rm data/img_align_celeba_resized.zip\n",
    "    \n",
    "if not os.path.isfile(\"data/attributes.npz\"):\n",
    "    print(\"téléchargement des atrtibuts\")\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NnR_3yVfZxXGBmaKmI95bE9_p-EOrWRf' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1NnR_3yVfZxXGBmaKmI95bE9_p-EOrWRf\" -O data/attributes.npz && rm -rf /tmp/cookies.txt\n",
    "\n",
    "print(\"Ok.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems that images have already been processed : data/img_align_celeba_resized\n",
      "It seems that attributes have already been processed : data/attributes.npz\n"
     ]
    }
   ],
   "source": [
    "# We download directly the processed attributes and processed images, so this line won't do nothing\n",
    "!python preprocess.py --img_path \"data/img_align_celeba\" --img_save_path \"data/img_align_celeba_resized\" --attr_path \"data/list_attr_celeba.txt\" --attr_save_path \"data/attributes.npz\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to train a classifier (this step is optional)\\\n",
    "Our classifier is available in our repo in models/classifier \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier: \n",
    "!python classifier.py --img_path=\"data/img_align_celeba_resized\" --attr_path=\"data/attributes.npz\" --save_path=\"models\" --attr=\"*\" \n",
    "\n",
    "# The classifier will be saved at models/classifier and will be trained over all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't wan't  to train your classifier you can download our trained classifier wit this case\n",
    "\n",
    "\n",
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "if not os.path.isdir(\"models/classifier\"):\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1nQiYHEspE1R2iTZCxu5oJ4_sUeUe54tt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1nQiYHEspE1R2iTZCxu5oJ4_sUeUe54tt\" -O models/classifier.zip && rm -rf /tmp/cookies.txt\n",
    "    !unzip -qq models/classifier.zip -d models\n",
    "    !rm models/classifier.zip\n",
    "\n",
    "print(\"Ok.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fader training\n",
    "\n",
    "It is now time to train the fader network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 03:04:01.694733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/huss/.local/lib/python3.8/site-packages/cv2/../../lib64:/home/huss/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-12-04 03:04:01.694761: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-04 03:04:03.439464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/huss/.local/lib/python3.8/site-packages/cv2/../../lib64:/home/huss/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-12-04 03:04:03.439489: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-04 03:04:03.439508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HussPC): /proc/driver/nvidia/version does not exist\n",
      "2022-12-04 03:04:03.440038: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "epoch : 0/1000, 0/50000,reonstruction loss : 0.40332, disc_loss : 0.69388, disc_accuracy = 0.46875, 7.05s\n",
      "epoch : 0/1000, 32/50000,reonstruction loss : 0.37947, disc_loss : 0.69164, disc_accuracy = 0.65625, 3.76s\n",
      "epoch : 0/1000, 64/50000,reonstruction loss : 0.37852, disc_loss : 0.68942, disc_accuracy = 0.59375, 3.43s\n",
      "epoch : 0/1000, 96/50000,reonstruction loss : 0.37691, disc_loss : 0.68512, disc_accuracy = 0.65625, 3.72s\n",
      "epoch : 0/1000, 128/50000,reonstruction loss : 0.38547, disc_loss : 0.68703, disc_accuracy = 0.59375, 4.37s\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 105, in <module>\n",
      "    recon_loss, dis_loss,  dis_acc= f.train_step((batch_x, batch_y))\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 947, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2956, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1853, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 499, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# On l'entraine sur l'attribut Male\n",
    "# Remove --classifier_path if you don't want to use a classifier\n",
    "\n",
    "!python train.py --img_path=\"data/img_align_celeba_resized\" --attr_path=\"data/attributes.npz\" --save_path=\"models/Male\" --attr=\"Male\"  --classifier_path=\"models/classifier\" --epoch_size 30000\n",
    "\n",
    "\"\"\"\n",
    "It will generate 3 directory in models/Male (the save_path)\n",
    "\n",
    "Ae_best_loss\n",
    "Ae_best_acc\n",
    "Fader_backup\n",
    "\n",
    "Fader_backup is used te take back training\n",
    "Ae_best_loss is used for inferation,  it's an AutoEncoder that had the best reconstruction loss\n",
    "Ae_best_acc is the AutoEncoder model that had the best accuracy given by the classifier\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some trained ( ~ 120 epochs) autoencoder (on 4 attributes) can be downloaded with the following command : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-04 14:50:51--  https://docs.google.com/uc?export=download&confirm=t&id=1ob775rr86kvzdbdBAy3IHWwbInr5HgGE\n",
      "Résolution de docs.google.com (docs.google.com)… 142.250.201.174, 2a00:1450:4007:806::200e\n",
      "Connexion à docs.google.com (docs.google.com)|142.250.201.174|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 303 See Other\n",
      "Emplacement : https://doc-08-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ktnol42o7g9lkncog0irg54uvgqcivu9/1670161800000/17381190629042448532/*/1ob775rr86kvzdbdBAy3IHWwbInr5HgGE?e=download&uuid=2b239e07-a1e6-4565-a182-2b8dcb94b6a9 [suivant]\n",
      "Avertissement : les jokers ne sont pas permis en HTTP.\n",
      "--2022-12-04 14:50:51--  https://doc-08-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ktnol42o7g9lkncog0irg54uvgqcivu9/1670161800000/17381190629042448532/*/1ob775rr86kvzdbdBAy3IHWwbInr5HgGE?e=download&uuid=2b239e07-a1e6-4565-a182-2b8dcb94b6a9\n",
      "Résolution de doc-08-00-docs.googleusercontent.com (doc-08-00-docs.googleusercontent.com)… 142.250.179.97, 2a00:1450:4007:807::2001\n",
      "Connexion à doc-08-00-docs.googleusercontent.com (doc-08-00-docs.googleusercontent.com)|142.250.179.97|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 270758839 (258M) [application/zip]\n",
      "Enregistre : «models/trained_models.zip»\n",
      "\n",
      "models/trained_mode 100%[===================>] 258,21M  13,4MB/s    ds 18s     \n",
      "\n",
      "2022-12-04 14:51:10 (14,0 MB/s) - «models/trained_models.zip» enregistré [270758839/270758839]\n",
      "\n",
      "Archive:  models/trained_models.zip\n",
      "   creating: models/Eyeglasses/\n",
      "  inflating: models/Eyeglasses/params.npy  \n",
      "  inflating: models/Eyeglasses/weights.index  \n",
      "  inflating: models/Eyeglasses/checkpoint  \n",
      "  inflating: models/Eyeglasses/history.npy  \n",
      "  inflating: models/Eyeglasses/weights.data-00000-of-00001  \n",
      "   creating: models/Male/\n",
      "  inflating: models/Male/weights.index  \n",
      "  inflating: models/Male/history.npy  \n",
      "  inflating: models/Male/checkpoint  \n",
      "  inflating: models/Male/params.npy  \n",
      "  inflating: models/Male/weights.data-00000-of-00001  \n",
      "   creating: models/Mouth/\n",
      "  inflating: models/Mouth/weights.index  \n",
      "  inflating: models/Mouth/params.npy  \n",
      "  inflating: models/Mouth/history.npy  \n",
      "  inflating: models/Mouth/checkpoint  \n",
      "  inflating: models/Mouth/weights.data-00000-of-00001  \n",
      "   creating: models/Young/\n",
      "  inflating: models/Young/checkpoint  \n",
      "  inflating: models/Young/weights.index  \n",
      "  inflating: models/Young/history.npy  \n",
      "  inflating: models/Young/params.npy  \n",
      "  inflating: models/Young/weights.data-00000-of-00001  \n",
      "Unzippig finished\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ob775rr86kvzdbdBAy3IHWwbInr5HgGE' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ob775rr86kvzdbdBAy3IHWwbInr5HgGE\" -O models/trained_models.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip models/trained_models.zip -d models\n",
    "!rm models/trained_models.zip\n",
    "print(\"Unzippig finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferation\n",
    "\n",
    "Now our model is trained, we can easer use the script use_fader.py, or the gui we implemented.\n",
    "\n",
    "We recommand you to use the GUI below, easier to use\n",
    "\n",
    "\n",
    "## Use_fader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 03:15:01.011504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/huss/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-12-04 03:15:01.011538: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"use_fader.py\", line 40, in <module>\n",
      "    ae = load_model(params.model_path, model_type = 'ae')\n",
      "  File \"/media/huss/CE6698AB66989635/Users/tendl/Desktop/M2/MLA/Projet/FD/utils.py\", line 85, in load_model\n",
      "    params = np.load(path + '/'+ params_name, allow_pickle = True).item()\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\", line 407, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'models.Male/Ae_best_loss/params.npy'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use_fader.py will create an image called gridOfCelibrity.jpg in the folder images which is an interpollation for different value of y \n",
    "!python use_fader.py --img_path=\"data/img_align_celeba_resized\" --attr_path=\"data/attributes.npz\" --model_path \"models/Male\" --alpha_min -1 --alpha_max 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 14:56:50.943415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/huss/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-12-04 14:56:50.943460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-04 14:57:07.563609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/huss/.local/lib/python3.8/site-packages/cv2/../../lib64:/home/huss/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-12-04 14:57:07.563636: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-04 14:57:07.563656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HussPC): /proc/driver/nvidia/version does not exist\n",
      "2022-12-04 14:57:07.564741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Exception ignored in: <function _CheckpointRestoreCoordinatorDeleter.__del__ at 0x7f163d4570d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huss/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py\", line 174, in __del__\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "!python gui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
